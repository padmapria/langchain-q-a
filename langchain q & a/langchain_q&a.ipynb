{
 "cells": [
  {
   "cell_type": "raw",
   "id": "228a4e65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T03:47:12.707368Z",
     "start_time": "2023-05-24T03:43:44.251797Z"
    }
   },
   "source": [
    "!pip uinstall --upgrade langchain openai -q\n",
    "\n",
    "##https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/unstructured_file.html\n",
    "!pip install unstructured -q\n",
    "!pip install unstructured[local-inference] -q\n",
    "!pip install detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2 -q\n",
    "!apt-get install poppler-utils\n",
    "\n",
    "#To use faiss\n",
    "pip install faiss-cpu\n",
    "\n",
    "#To read constants from .env file\n",
    "!pip install python-dotenv\n",
    "\n",
    "#To use huggingface transformer library\n",
    "!pip install huggingface_hub\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf1aafd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T11:25:13.392423Z",
     "start_time": "2023-05-24T11:25:13.359490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUGGINGFACEHUB_API_TOKEN\n",
      "PINECONE_API_KEY\n",
      "PINECONE_ENV\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "import os,openai\n",
    "\n",
    "env_vars = dotenv_values('.env')\n",
    "\n",
    "for key in env_vars.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87035ea",
   "metadata": {},
   "source": [
    "## Reading data from url and writing to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a3b6dcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T11:22:54.788298Z",
     "start_time": "2023-05-24T11:22:54.769063Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_data_from_url(url,fileName):\n",
    "    res = requests.get(url)\n",
    "\n",
    "    with open(fileName, \"w\") as f:\n",
    "        f.write(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f6a745",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T04:56:18.383416Z",
     "start_time": "2023-05-24T04:56:18.377385Z"
    }
   },
   "source": [
    "## Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48b7de7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T10:45:54.972469Z",
     "start_time": "2023-05-24T10:45:54.004794Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://python.langchain.com/en/latest/modules/indexes/getting_started.html\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "def load_textFile(fileName):\n",
    "    loader = TextLoader(fileName)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "    \n",
    "    \n",
    "#To load a directory and create document\n",
    "#https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/file_directory.html\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "def load_dir(directory):\n",
    "    loader = DirectoryLoader(directory)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b8065",
   "metadata": {},
   "source": [
    "## Document splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b06ea3ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T10:45:56.048712Z",
     "start_time": "2023-05-24T10:45:54.974508Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/huggingface_length_function.html\n",
    "\n",
    "from transformers import GPT2TokenizerFast\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "def split_docs(documents,chunk_size, chunk_overlap):\n",
    "    text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(tokenizer,chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94917052",
   "metadata": {},
   "source": [
    "## Creating Embeddings and storing in vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d43fad79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T10:46:00.378919Z",
     "start_time": "2023-05-24T10:46:00.364919Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://python.langchain.com/en/latest/modules/models/text_embedding/examples/instruct_embeddings.html\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
    "from langchain.vectorstores import FAISS\n",
    "def create_faiss_index(docs):\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0a4dc2",
   "metadata": {},
   "source": [
    "## Search the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e074bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T10:46:00.394918Z",
     "start_time": "2023-05-24T10:46:00.380919Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_similar_doc_from_index(index,query,k):\n",
    "    similar_docs = index.similarity_search(query, k=k)\n",
    "    return similar_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613ff2f",
   "metadata": {},
   "source": [
    "## Create QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed2ad1d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T10:47:20.014130Z",
     "start_time": "2023-05-24T10:47:19.648499Z"
    }
   },
   "outputs": [],
   "source": [
    "##https://python.langchain.com/en/latest/use_cases/question_answering.html\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", \n",
    "                   model_kwargs={\"temperature\":0.8, \"max_length\":64},\n",
    "                  huggingfacehub_api_token = env_vars['HUGGINGFACEHUB_API_TOKEN'] )\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "def get_answer(index,query):\n",
    "    ip_docs = find_similar_doc_from_index(index,query, k=3)\n",
    "    answer = chain.run(input_documents=ip_docs, question=query)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c23596",
   "metadata": {},
   "source": [
    "## Test the above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85ca0919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T11:22:58.719459Z",
     "start_time": "2023-05-24T11:22:58.320255Z"
    }
   },
   "outputs": [],
   "source": [
    "# For data from a url\n",
    "url = \"https://raw.githubusercontent.com/hwchase17/langchain/master/docs/modules/state_of_the_union.txt\"\n",
    "fileName = \"state_of_the_union.txt\"\n",
    "documents= get_data_from_url(url,fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46867e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T11:23:30.103031Z",
     "start_time": "2023-05-24T11:22:59.709156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning is the foundation of countless important applications, including web search, email anti-spam'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For data from directory\n",
    "data_dir ='data'\n",
    "documents = load_dir(data_dir)\n",
    "\n",
    "docs = split_docs(documents,chunk_size=300, chunk_overlap=0)\n",
    "index = create_faiss_index(docs)\n",
    "\n",
    "query = \"what is machine learning\"\n",
    "get_answer(index,query)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36319e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
